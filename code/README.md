# Instructions
0. Download the corpus and put all the text files in a folder "corpus"
1. Create a tokenizer from the corpus and save it in a file
   1. python create_tokenizer.py --vocab_size 10000 --corpus_dir "corpus" --tokenizer_file "tokenizer.pickle"
